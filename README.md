# HW2 Car plates OCR

**Введенский Вячеслав, MADE-ML-22**

Начал с baseline Алексея maskrcnn_resnet50_fpn.

## OCR

### Подготовка и обучение

Отдельно обучил OCR из бейзлайна на размеченых номерах из трейна с использованием аналогичной аугментации (обучение на bbox+poly).
Добавил преобразование всего и вся в заглавную латиницу.
Увеличил размер скрытого слоя. Обучение - 5 эпох.
CRNN (output=20,dropout=0.3, hidden=384).

Пробовал разные варианты, этот показался стабильным. И дальше пробовал уже настраивать детекцию/сегментацию.

### Фильтрация

Обратил внимание, что модель детекции часто находит области, в которых нет номера. Но из-за отсутствия любого фильтра на выходе - OCR с радостью находит там номер.

В baseline ситуация ухудшалась тем, что там делалось предсказание от bbox и polygon и результаты складывались.
Добавил softmax на результат CRNN. И каждый результат предсказания добавлял в список предсказанных номеров отдельно.
После этого при декодировании предсказания делал следующее

``` python
label = np.argmax(pred[i])
if pred[i][label]<0.7:
    label = 0
```

Таким образом если модель не была уверена в тексте номера, получали или короткий номер или ничего. После этого был фильтр на короткий номер `>= 7` символов.

Для каждого номера добавлял левый край и центр номера. Левый край для упорядочивания, а центр номера для поиска дублей.
Если находились несколько номеров с близкими центрами, то выбирался более длинный (Это будет полезным далее).

``` python
preds_poly = F.softmax(preds_poly,dim=2)
preds_bbox = F.softmax(preds_bbox,dim=2)
text_poly = decode(preds_poly, alphabet)[0]
results_to_sort.append((x_min, text_poly, (x0+x1+x2+x3)/4,(y0+y1+y2+y3)/4))
text_bbox = decode(preds_bbox, alphabet)[0]
results_to_sort.append((x_min, text_bbox, (x_min+x_max)/2,(y_min+y_max)/2))
```

### Валидировался

после каждой эпохи считал Левенштейна на множествах номеров:

- на отложенных изображениях.
- на дополнительном датасете, который выдали.
- из практики семинара 9 - взял датасет. в нем оставил только номера "плохие"( которые плохо читаемы) и считал на них.
- выбрал несколько номеров, в которых была большая ошибка и смотрел что выдает на них.

В итоге отобрал 1 OCR модель и все остальное эксперементировал с ней.

### Неудачные попытки

1. Обучать OCR на размеченных номерах + предсказанных моделью детекции номеров.
2. Обучать OCR только на номерах предсказанных моделью детекции номеров.
Была гипотеза, что в таком случае кривые номера не будут сюрпризом для модели.
3. Перед распознованием делать номера одноцветными и выравнивать яркость.
Хотел сделать, чтобы все изображения были в одной цветовой политре, но похоже, что при переходе к серому теряли часть информации.
4. Пробовал bidirectional GRU.
Вроде как не ожидал, что двунаправленность в этой задаче даст прирост. Но такая модель училась быстрее, лучше распозновала некоторые номера (например регион из 3х цифр), но в среднем не дала улучшение.
5. Пробовал играть с количеством признаков на выходе от 16-20.
Думал, что 20 - избыточно. Но в итоге не нашел плюсов в уменьшении.
Возможно, что на 4,5 пункт мало времени потратил.

## MaskRCNN

Модель из baseline. Попробовал разморозить все слои. Считалось дольше и для дальнейших экспериментов это убрал, но в итоговый сабмит попал такой вариант. Использовал `Adam + CosineAnnealingWarmRestarts`.

### Валидидация

Делал предсказание зафиксированной моделью на отложенной выборке и считал Левенштейна по склееной строке.

## Итог

1. Ресайз исходного изображения(кубическая интерполяция, ограничение 1024х1024).
2. Поиск всех bbox и polygon.
3. Независимый OCR на них с фильтрацией уверенности.

Обратил внимание, что в выходном файле много отсутствующих предсказаний. Добавил дополнительный блок:
Если обыный поиск не нашел номер, то из исходного изображения кроп 9 меньших и поиск в каждом из них.

``` python
res_to_sort.append(validate_image_crop(fn,0.25,0.25,0.75,0.75))
res_to_sort.append(validate_image_crop(fn,0,0,0.5,0.5))
res_to_sort.append(validate_image_crop(fn,0.5,0,1,0.5))
res_to_sort.append(validate_image_crop(fn,0,0.5,0.5,1))
res_to_sort.append(validate_image_crop(fn,0.5,0.5,1,1))

res_to_sort.append(validate_image_crop(fn,0.25,0,0.75,0.5))
res_to_sort.append(validate_image_crop(fn,0.5,0.25,1,0.75))
res_to_sort.append(validate_image_crop(fn,0.25,0.5,0.75,1))
res_to_sort.append(validate_image_crop(fn,0,0.25,0.5,0.75))
```

4. Добавил отказ предсказывать номера на границах кропа (мог разрезаться).
5. Сжатие итогового списка номеров по их центрам и выбор самого длинного.

### Неудачные варианты

1. Приводить к "серому".
2. Выравнивание яркости.
3. Не стал резать на куски при обучении, так как были картинки с разными DPI и где-то 512х512 - могло быть размером с номер.

## Самое неудачное, куда ушло всё время...

Подумал, что у нас исходные изображения все разных размеров и модели сложно детектировать номера на исходном. Поэтому решил усложнить пайплайн:

1. Ресайз исходного изображения до 2000 по большей стороне.
Как оказалось попытка найти все машины (когда их очень много) на большом изображении приводит к нехватке памяти GPU.
2. Использование предобученной `maskrcnn_resnet50_fpn` для поиска всего автотранспорта, что может иметь номер.
Идея была в том, что все машины более/менее одних пропорций. И если выделить машину, ресайз ее до одинаковых размеров, то найти номера будет легче.
3. Модель детекции номеров обучалась на этих кропах каждой машины, если в ней был номер.
4. Если номер находился, то OCR, ранее выбранной моделью.
5. Объединение всех предсказаний в один список, его сортировка и фильтрации на дубли.

Как оказалось качество распознования у такого пайплайна  было **слишком хорошим**. Гораздо выше, чем качество разметки train (как я понимаю и test'а тоже).
Качество проверял глазами на тех примерах, где была большая ошибка. Если на фотографии машина была далеко или просто торчал кусочек номера - он был распознан. А как оказалось на валидации - на большом количестве изображений отмечены были только часть номеров.

6. Попытался ввести эвристики, которые бы позволяли игнорировать часть номеров.
7. Добавил подсчёт видимой площади машины (корень из площади), которая считалась по найденой маске. Все машины сортировались по этому значению. 5% нижних просто удалялись (как слишком маленькие объекты). А в работу шли все машины с площадью выше медианы.

**Результата это не дало!**
То есть если бы стояла цель написать детектор всех номеров - этот подход зашел очень хорошо. Но написать распознование номеров, которые бы были размечены аналогично train/test было сложнее.

### Была идея, но не стал пробовать

1. Хотел добавить аугментаций больше для первой версии пайплайна. Но так увлекательно было делать "улучшеную" версию, что уже не стал отвлекаться.
2. Была идея **обучить модель, которая бы предсказывала будет ли номер этой машины размечен** аналогично train/test.
   
Хотел взять размеры машин, номеров, площади перекрытия, площади видимых машинок, расстояние между "главной машиной" на кадре. Все это скормить какой-нибудь модели (типа бустинга) и научиться предсказывать нужно ли в submission включать номер с этой машины.
Положительный класс у нас был. А отрицательный надо было сгенерировать. по этим же картинкам. Но на это уже не хватило сил и времени.

**Спасибо за внимание!**
